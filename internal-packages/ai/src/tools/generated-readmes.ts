/**
 * Auto-generated tool README content
 * Generated by scripts/generate-tool-readmes.ts
 * DO NOT EDIT MANUALLY
 * 
 * README Hash: 3ea06f7d29059c9083b9ed45fb7e9c043f4061b00ce7d65a7189d1f348e221ae
 */

export const toolReadmes = {
  "check-spelling-grammar": "# Check Spelling & Grammar\n\n*README content not available*",
  "extract-factual-claims": "# Extract Factual Claims\n\n*README content not available*",
  "fact-checker": "# Fact Checker Tool\n\nThe fact-checker tool is designed to verify the accuracy of specific factual claims. It works in tandem with the extract-factual-claims tool to provide a complete fact-checking pipeline.\n\n## How it Works\n\nThis tool takes a specific claim and verifies its accuracy by:\n\n1. Analyzing the claim for accuracy\n2. Providing a verdict (true, false, partially-true, unverifiable, outdated)\n3. Explaining the reasoning with evidence\n4. Suggesting corrections if needed\n\n## Separation of Concerns\n\nSimilar to the forecasting system, fact-checking is split into two tools:\n\n- **extract-factual-claims**: Finds and scores factual claims in documents\n- **fact-checker**: Verifies the accuracy of specific claims\n\nThis separation allows:\n- Better performance through parallel processing\n- Cleaner interfaces and testing\n- Flexibility to use either tool independently\n- Cost optimization by only verifying high-priority claims\n\n## Example Usage\n\n```typescript\nconst result = await factCheckerTool.execute({\n  claim: \"The Great Wall of China is visible from space\",\n  context: \"Common misconception about landmarks\"\n});\n\n// Result includes:\n// - verdict: 'false'\n// - confidence: 'high'\n// - explanation: \"This is a common myth. The Great Wall is not visible...\"\n// - evidence: [\"NASA has confirmed...\", \"Astronauts have stated...\"]\n// - corrections: \"The Great Wall is not visible from space without aid\"\n```\n\n## Integration with FactCheckAnalyzerJob\n\nThe FactCheckAnalyzerJob orchestrates both tools:\n\n1. Extracts claims using extract-factual-claims\n2. Scores and filters claims based on importance, controversiality, and verifiability\n3. Verifies high-priority claims using fact-checker\n4. Generates comments combining extraction scores and verification results",
  "check-math-with-mathjs": "# Check Math with MathJS\n\n*README content not available*",
  "check-math": "# Check Mathematical Accuracy\n\n*README content not available*",
  "check-math-hybrid": "# Hybrid Mathematical Checker\n\n*README content not available*",
  "extract-math-expressions": "# Extract Mathematical Expressions\n\n*README content not available*",
  "extract-forecasting-claims": "# Extract Forecasting Claims\n\n*README content not available*",
  "document-chunker": "# Intelligent Document Chunker\n\n*README content not available*",
  "fuzzy-text-locator": "# Fuzzy Text Locator\n\nA powerful text location tool that finds text within documents using multiple search strategies, from exact matching to AI-powered semantic search.\n\n## Overview\n\nThe Fuzzy Text Locator uses a cascade of search strategies to find text positions in documents:\n\n1. **Exact Match** - Fastest, requires perfect character-for-character match\n2. **Quote-Normalized Match** - Handles smart quotes, apostrophes, and similar variations\n3. **Partial Match** - Finds the longest matching substring for truncated text\n4. **Fuzzy Match (uFuzzy)** - Tolerates typos, case differences, and minor variations\n5. **LLM Fallback** - Uses AI to find paraphrased or semantically similar text\n\n## Key Features\n\n- **Multi-strategy approach**: Tries simple strategies first, falls back to complex ones\n- **Character-level precision**: Returns exact start/end positions in the document\n- **Confidence scoring**: Each strategy provides a confidence score (0.0-1.0)\n- **Quote normalization**: Handles smart quotes, em-dashes, ellipses automatically\n- **Partial matching**: Finds truncated quotes or partial text\n- **Semantic search**: Optional LLM fallback for paraphrased content\n\n## Usage\n\n### Basic Example\n\n```typescript\nimport { findTextLocation } from '@/tools/fuzzy-text-locator';\n\nconst result = await findTextLocation(\n  \"sample document\",\n  \"This is a sample document with some text.\",\n  { normalizeQuotes: true }\n);\n// Returns: { startOffset: 10, endOffset: 25, quotedText: \"sample document\", strategy: \"exact\", confidence: 1.0 }\n```\n\n### Options\n\n```typescript\ninterface TextLocationOptions {\n  // Basic options\n  normalizeQuotes?: boolean;    // Handle quote/apostrophe variations\n  partialMatch?: boolean;       // Match partial/truncated text\n  caseSensitive?: boolean;      // Case-sensitive matching (default: false)\n  \n  // Fuzzy matching options\n  maxTypos?: number;           // Maximum typos allowed in fuzzy search\n  \n  // LLM options\n  useLLMFallback?: boolean;    // Use AI for semantic search\n  llmContext?: string;         // Context to help AI understand\n  pluginName?: string;         // For tracking/logging\n}\n```\n\n## Search Strategies\n\n### Exact Match\n- **Speed**: Fastest\n- **Use case**: When you have the exact text\n- **Confidence**: 1.0\n\n### Quote-Normalized Match\n- **Speed**: Fast\n- **Use case**: Text with smart quotes, apostrophes, em-dashes\n- **Confidence**: 1.0\n- **Example**: \"don't\" matches \"don't\"\n\n### Partial Match\n- **Speed**: Fast\n- **Use case**: Truncated quotes or first part of long text\n- **Confidence**: 0.65-0.7\n- **Example**: \"The research shows\" matches longer quote starting with those words\n\n### Fuzzy Match (uFuzzy)\n- **Speed**: Medium\n- **Use case**: Text with typos, case differences, minor variations\n- **Confidence**: 0.6-0.95\n- **Example**: \"mashine learning\" matches \"machine learning\"\n\n### LLM Fallback\n- **Speed**: Slow (API call)\n- **Use case**: Paraphrased text, semantic similarity\n- **Confidence**: 0.5-0.9\n- **Example**: \"car drove fast\" matches \"automobile moved swiftly\"\n\n## Architecture\n\n```\nfuzzy-text-locator/\nâ”œâ”€â”€ index.ts          # Main tool class and exports\nâ”œâ”€â”€ core.ts           # Core search orchestration logic\nâ”œâ”€â”€ exactSearch.ts    # Simple exact string matching\nâ”œâ”€â”€ uFuzzySearch.ts   # Fuzzy matching with uFuzzy library\nâ”œâ”€â”€ llmSearch.ts      # LLM-based semantic search\nâ”œâ”€â”€ types.ts          # Shared TypeScript types\nâ””â”€â”€ tests/            # Comprehensive test suite\n```\n\n## Testing\n\nThe tool includes a comprehensive test suite with 80+ test cases covering:\n- Basic exact matching\n- Quote and punctuation variations\n- Whitespace handling\n- Unicode characters\n- Partial matches\n- Typos and fuzzy matching\n- Long documents\n- Edge cases\n\nRun tests:\n```bash\nnpm test -- src/tools/fuzzy-text-locator/tests/\n```\n\n## Performance Considerations\n\n- Strategies are tried in order from fastest to slowest\n- Most searches complete in < 10ms without LLM\n- LLM fallback adds 500-2000ms depending on text length\n- For large documents, consider chunking for better performance\n\n## Integration with Plugins\n\nThe tool is designed to be used by analysis plugins:\n\n```typescript\nimport { findTextLocation } from '@/tools/fuzzy-text-locator';\n\n// In your plugin\nconst location = await findTextLocation(\n  errorText,\n  documentText,\n  {\n    normalizeQuotes: true,\n    useLLMFallback: true,\n    pluginName: 'my-plugin'\n  }\n);\n```\n\n## Future Improvements\n\n- [ ] Add caching for repeated searches\n- [ ] Implement parallel search strategies\n- [ ] Add support for regex patterns\n- [ ] Optimize for very large documents\n- [ ] Add more language-specific normalizations",
  "detect-language-convention": "# Detect Language Convention\n\n*README content not available*",
  "forecaster": "# Forecaster Tool\n\nA tool that generates probability forecasts using multiple independent Claude analyses.\n\n## Overview\n\nThe Forecaster Tool asks Claude to make independent probability assessments of a given question, then aggregates them using statistical methods to produce a final forecast with confidence levels.\n\n## Usage\n\n### API Endpoint\n```\nPOST /api/tools/forecaster\n```\n\n### Input Schema\n```typescript\n{\n  question: string;         // The question to forecast (1-500 chars)\n  context?: string;         // Additional context (max 1000 chars)\n  numForecasts?: number;    // Number of forecasts to generate (3-20, default: 6)\n  usePerplexity?: boolean;  // Whether to use Perplexity for research (default: false)\n}\n```\n\n### Output Schema\n```typescript\n{\n  probability: number;      // Aggregated probability (0-100)\n  description: string;      // Description of the forecast and reasoning\n  confidence: 'low' | 'medium' | 'high';  // Based on forecast agreement\n  individualForecasts: Array<{\n    probability: number;\n    reasoning: string;\n  }>;\n  statistics: {\n    mean: number;\n    median: number;\n    stdDev: number;\n    agreement: number;    // % of forecasts within 10 points of median\n  };\n}\n```\n\n## Example\n\n```typescript\nconst response = await fetch('/api/tools/forecaster', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer YOUR_TOKEN'\n  },\n  body: JSON.stringify({\n    question: \"Will AGI be achieved by 2030?\",\n    context: \"Recent advances in LLMs have accelerated AI progress\",\n    numForecasts: 6\n  })\n});\n\nconst result = await response.json();\n// {\n//   success: true,\n//   toolId: 'forecaster',\n//   result: {\n//     probability: 35,\n//     description: \"Based on 6 independent analyses...\",\n//     confidence: 'medium',\n//     individualForecasts: [...],\n//     statistics: {...}\n//   }\n// }\n```\n\n## Cost\n\nApproximately $0.05 per forecast (6 Claude calls).\n\n## Implementation Details\n\n- Uses multiple independent Claude calls to reduce bias\n- Removes statistical outliers before aggregation\n- Confidence levels based on forecast agreement:\n  - High: >66% of forecasts within 10 points of median\n  - Medium: 33-66% agreement\n  - Low: <33% agreement",
  "link-validator": "# Link Validator Tool\n\n## What This Tool Does\n\nThe Link Validator tool extracts and validates all external links in documents, providing detailed accessibility status and error categorization. It offers comprehensive link health analysis without using any LLM calls.\n\nAlso known as the \"Simple Link Validator\" agent, this tool checks all external links in documents and reports their accessibility status with clear error categorization and context-aware messaging about link health.\n\n## Core Capabilities\n\n- **Automatic Link Detection**: Finds all URLs in document content (markdown links, HTML links, plain URLs)\n- **Multi-Strategy Validation**: Tests HEAD requests first, falls back to GET requests with different user agents\n- **Smart Error Classification**: Categorizes failures as 403 Forbidden, 404 Not Found, timeouts, network errors, etc.\n- **Highlight Generation**: Creates positioned comments for broken links in documents\n- **Context-Aware Reporting**: Adapts messaging based on predominant error types\n\n## Usage\n\n```typescript\nimport { linkValidator } from '@roast/ai/server';\n\n// Basic usage\nconst result = await linkValidator.run({\n  text: documentContent,\n  maxUrls: 20  // optional, defaults to 20\n}, {\n  logger: console\n});\n\n// Result includes:\n// - urls: string[] - all URLs found\n// - validations: detailed validation results for each URL\n// - summary: statistics about link health\n```\n\n## Output Structure\n\n### Summary Statistics\n```typescript\n{\n  totalLinks: number,\n  workingLinks: number,\n  brokenLinks: number,\n  errorBreakdown: {\n    NotFound: number,\n    Forbidden: number,\n    Timeout: number,\n    NetworkError: number,\n    // ... other error types\n  }\n}\n```\n\n### Individual Link Validations\nEach URL validation includes:\n- `url`: Original URL\n- `finalUrl`: URL after redirects (if different)\n- `accessible`: Boolean indicating if link works\n- `error`: Error details if link failed\n- `details`: Response details if link succeeded\n\n## Error Types\n\n- **NotFound** (404): Page doesn't exist\n- **Forbidden** (403): Access denied\n- **Timeout**: Request timed out\n- **NetworkError**: DNS, SSL, or connection errors\n- **RateLimited** (429): Too many requests\n- **ServerError** (5xx): Server-side errors\n- **Unknown**: Other HTTP errors\n\n## Advanced Features\n\n### Highlight Generation\nGenerate document highlights for link issues:\n\n```typescript\nimport { generateLinkHighlights } from '@roast/ai/tools/link-validator/linkHighlightGenerator';\n\nconst highlights = generateLinkHighlights(\n  validationResults,\n  urls,\n  documentContent,\n  targetHighlights // optional limit\n);\n```\n\n### Analysis Report Generation\nCreate detailed analysis reports:\n\n```typescript\nimport { generateLinkAnalysisAndSummary } from '@roast/ai/tools/link-validator/linkAnalysisReporter';\n\nconst { analysis, summary, grade } = generateLinkAnalysisAndSummary(\n  validationResults,\n  documentTitle\n);\n```\n\n## Example Messages\n\n**Access-restriction focused** (when most errors are 403s):\n> ðŸš« Links Blocked by Access Restrictions  \n> Found 8 inaccessible URLs, primarily due to access restrictions. Many websites block automated access, even though the content exists.\n\n**Broken-links focused** (when most errors are 404s):\n> âŒ Broken Links Detected  \n> Found 6 broken or non-existent URLs. These may be hallucinated links or references to content that has moved or been deleted.\n\n## When to Use\n\n**Ideal for**: \n- Research papers with citations\n- Blog posts with external references\n- News articles\n- Documentation with external links\n- Any content where link quality affects credibility\n\n**Less suitable for**: \n- Documents without external links\n- Creative writing\n- Internal documentation with private URLs\n\n## Technical Notes\n\n- Uses respectful validation with delays between requests\n- Tries multiple user agents to handle basic bot detection  \n- 10-second timeout per request for performance\n- Processes URLs in batches of 10 to avoid overwhelming servers\n- No prescriptive recommendations - focuses on status reporting only\n- Zero LLM usage - all validation is done directly",
  "perplexity-research": "# Perplexity Research Tool\n\nA research assistant tool that uses the Perplexity API to search for up-to-date information on any topic. Perfect for gathering context, finding recent developments, and collecting sources for analysis and forecasting tasks.\n\n## Overview\n\nThe Perplexity Research Tool leverages Perplexity AI's search capabilities to:\n\n1. **Search across the web** - Accesses current information from multiple sources\n2. **Summarize findings** - Provides concise summaries of research results  \n3. **Categorize sources** - Ranks sources by relevance (high/medium/low)\n4. **Extract key findings** - Highlights the most important insights\n5. **Support focus areas** - Tailors searches to specific domains (academic, news, technical, etc.)\n\n## Key Features\n\n- **Real-time search**: Accesses current information, not limited to training data\n- **Source categorization**: Automatically ranks sources by relevance\n- **Configurable results**: Control number of sources (3-10)\n- **Focus area targeting**: Optimize searches for different domains\n- **Key findings extraction**: Automatically identifies important insights\n- **Source metadata**: Full URLs, titles, and snippets for verification\n\n## Usage\n\n### Basic Research Query\n\n```typescript\nimport { perplexityResearchTool } from '@roast/ai';\n\nconst result = await perplexityResearchTool.execute({\n  query: \"What are the latest developments in quantum computing error correction?\",\n  maxSources: 5,\n  focusArea: \"academic\"\n});\n```\n\n### Focus Areas\n\n- **`general`** - Broad web search across all sources\n- **`academic`** - Prioritize scholarly articles and research papers\n- **`news`** - Focus on recent news and current events\n- **`technical`** - Emphasize technical documentation and specifications\n- **`market`** - Target financial and market information\n\n### Response Format\n\n```typescript\ninterface ResearchResult {\n  query: string;\n  summary: string;\n  sources: Array<{\n    title: string;\n    url: string;\n    snippet: string;\n    relevance: 'high' | 'medium' | 'low';\n  }>;\n  keyFindings: string[];\n  timestamp: string;\n}\n```\n\n## Integration with Analysis Workflows\n\nThis tool is particularly valuable for:\n\n### Forecasting Tasks\n- Gather recent developments on prediction topics\n- Find expert opinions and analysis\n- Collect baseline facts for probability assessments\n\n### Fact-Checking\n- Verify claims against current sources\n- Find supporting or contradicting evidence\n- Access recent updates to evolving topics\n\n### Context Building\n- Research background information for document analysis\n- Find related developments and trends\n- Gather expert perspectives\n\n## Example Queries\n\n### Technology Research\n```\n\"Latest breakthroughs in large language model efficiency improvements\"\n```\n\n### Market Analysis\n```  \n\"Current trends in renewable energy investment and policy changes 2024\"\n```\n\n### Scientific Updates\n```\n\"Recent advances in CRISPR gene editing safety and regulations\"\n```\n\n## Cost and Performance\n\n- **Response time**: 2-5 seconds depending on query complexity\n- **Source diversity**: Typically returns 5-10 high-quality sources\n- **Update frequency**: Accesses information updated within hours or days\n- **Rate limits**: Managed automatically with backoff strategies\n\n## Best Practices\n\n1. **Be specific**: More specific queries yield better, more relevant results\n2. **Use focus areas**: Choose the appropriate focus area for your research domain\n3. **Verify sources**: Always check the provided URLs for full context\n4. **Combine with other tools**: Use results to inform fact-checking or forecasting analyses\n5. **Track timestamps**: Note when research was conducted for time-sensitive topics\n\n## Limitations\n\n- Dependent on Perplexity API availability and rate limits\n- Results quality varies with query specificity\n- May not access paywalled or restricted content\n- Focus areas are suggestions, not strict filters"
} as const;

export type ToolId = keyof typeof toolReadmes;

export function getToolReadme(toolId: ToolId): string {
  return toolReadmes[toolId] || `# ${toolId}\n\n*README content not available*`;
}

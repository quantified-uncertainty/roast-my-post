/**
 * Auto-generated tool README content
 * Generated by scripts/generate-tool-readmes.ts
 * DO NOT EDIT MANUALLY
 * 
 * README Hash: c27ba98a1eec20ac7124a229c4bcc63091878c4e609ed56b6569ec9f340d8a44
 */

export const toolReadmes = {
  "check-spelling-grammar": "# Check Spelling & Grammar\n\nA sophisticated proofreading tool that combines language convention detection with Claude-based error analysis. Features adjustable strictness levels and automatic US/UK English convention handling.\n\n## How It Works\n\nFirst detects the document's language convention (US/UK/mixed) using the detect-language-convention tool, then sends text to Claude with detailed instructions for error detection. The tool uses importance scoring (0-100) and confidence levels to prioritize errors, with configurable strictness levels (minimal/standard/thorough) that adjust the error detection threshold.\n\n## Capabilities & Limitations\n\n**Strengths:** Intelligent convention handling - can enforce specific US/UK spelling or adapt to mixed conventions. Three strictness levels for different use cases. Returns exact error text with concise corrections, importance scores, and confidence ratings. Provides explanations only for complex errors to reduce noise.\n\n**Limitations:** Costs ~$0.01-0.02 per check using Claude Haiku. Limited to 50 errors by default (configurable). Line numbers are approximate. For exact position finding, combine with fuzzy-text-locator tool.\n\n## Technical Details\n\n- **Strictness levels:** minimal (importance ‚â•51), standard (‚â•26), thorough (‚â•0)\n- **Convention modes:** US, UK, or auto-detect with mixed convention support\n- **Error scoring:** importance (0-100), confidence (0-100), with contextual descriptions\n- **Location:** Implementation in `/internal-packages/ai/src/tools/check-spelling-grammar/`",
  "extract-factual-claims": "# Extract Factual Claims\n\nAI-powered tool for extracting and categorizing factual claims from text with confidence scores and verifiability assessment.\n\n## What it does\n\n- **Identifies Claims**: Extracts factual statements from text automatically\n- **Classifies Types**: Categorizes as factual, statistical, historical, scientific, or other\n- **Assesses Verifiability**: Determines if claims can be verified through external sources\n- **Provides Confidence**: Scores each claim for extraction reliability\n- **Handles Multiple Claims**: Processes entire documents in a single operation\n\n## Claim Types\n\n**Factual**: General statements about events, people, or things (\"Paris is the capital of France\")\n**Statistical**: Numerical data and measurements (\"Unemployment rose 2.3% in 2023\")\n**Historical**: Past events and dates (\"World War II ended in 1945\")\n**Scientific**: Research findings and technical facts (\"Water boils at 100¬∞C at sea level\")\n**Other**: Claims that don't fit standard categories\n\n## Use Cases\n\n- **Research Analysis**: Extract claims from academic papers and reports\n- **Content Verification**: Identify statements needing fact-checking\n- **Information Organization**: Structure factual data from large documents\n- **Quality Assurance**: Review content for proper claim support\n\n## Integration\n\nWorks well with:\n- **Fact Checker Tool**: Verify extracted claims for accuracy\n- **Perplexity Research Tool**: Find sources for claim verification\n- **Link Validator Tool**: Check referenced sources\n\n## Important Notes\n\n- AI may extract opinions as factual claims - always review results\n- Cannot verify claim accuracy (only identifies and categorizes them)\n- Effectiveness varies with text complexity and writing style\n- Check confidence scores - higher scores indicate more reliable extraction\n- Best used as first pass before human review\n\n## Limitations\n\nMay miss context-dependent or implicit claims. Performance varies by domain and document structure.",
  "fact-checker": "# Fact Checker\n\nAI-powered tool for verifying the accuracy of specific factual claims with detailed evidence and reasoning.\n\n## What it does\n\n- **Verifies Claims**: Analyzes specific claims for accuracy and truthfulness\n- **Provides Verdicts**: Returns true, false, partially-true, unverifiable, or outdated\n- **Explains Reasoning**: Detailed explanations with supporting evidence\n- **Suggests Corrections**: Offers accurate alternatives for false claims\n- **Assesses Confidence**: Indicates reliability of the verification\n\n## Verification Process\n\n1. Analyzes the claim against current knowledge and sources\n2. Determines accuracy with nuanced verdicts (not just true/false)\n3. Provides evidence and reasoning for the verdict\n4. Suggests corrections when claims are inaccurate or misleading\n\n## Verdict Types\n\n**True**: Claim is accurate and supported by reliable evidence\n**False**: Claim is demonstrably incorrect\n**Partially-true**: Claim contains accurate elements but is misleading or incomplete\n**Unverifiable**: Cannot be verified with available sources\n**Outdated**: Was true but no longer current\n\n## Use Cases\n\n- **Individual Claim Verification**: Check specific statements for accuracy\n- **Content Review**: Verify key claims in articles or documents\n- **Research Validation**: Confirm factual assertions in academic work\n- **Misinformation Detection**: Identify and correct false information\n\n## Integration\n\nWorks with **Extract Factual Claims** tool:\n1. Extract claims from documents\n2. Prioritize high-importance claims\n3. Verify selected claims for accuracy\n4. Generate comprehensive fact-check reports\n\n## Important Notes\n\n- Focuses on verifying specific claims (not extracting them)\n- Provides evidence-based reasoning for all verdicts\n- Best used for high-priority or controversial claims\n- Always includes confidence levels for reliability assessment\n\n## Limitations\n\nEffectiveness depends on claim specificity and available evidence sources. Cannot verify highly specialized or very recent claims.",
  "check-math-with-mathjs": "# Check Math with MathJS\n\nAn agentic mathematical verification tool that gives Claude access to MathJS for computational verification. Claude acts as an agent that can make multiple calculation attempts using MathJS tools before providing a verdict. The tool now features **deterministic numeric comparison** at the code level for consistent approximation handling.\n\n## How It Works\n\nThe tool operates in two modes:\n\n1. **Direct Evaluation Mode:** For simple equality statements (e.g., \"2 + 2 = 4\"), the tool attempts direct MathJS evaluation with deterministic comparison logic\n2. **Agent Mode:** For complex statements, Claude receives access to two tools: `evaluate_expression` (for MathJS calculations) and `provide_verdict` (for final judgment)\n\n## Deterministic Numeric Comparison\n\nThe tool now includes code-level deterministic comparison logic that automatically handles mathematical approximations:\n\n### Approximation Rules\n- **Precision-based rounding:** Values are compared based on the decimal precision shown in the statement\n- **Automatic acceptance:** Reasonable approximations are accepted without LLM interpretation\n  - ‚úÖ \"10/3 = 3.33\" ‚Üí Accepted (3.333... rounds to 3.33)\n  - ‚úÖ \"œÄ = 3.14\" ‚Üí Accepted (3.14159... rounds to 3.14)\n  - ‚úÖ \"‚àö2 = 1.414\" ‚Üí Accepted (1.41421... rounds to 1.414)\n  - ‚ùå \"œÄ = 3.0\" ‚Üí Rejected (3.14159... rounds to 3.1, not 3.0)\n  - ‚ùå \"10/3 = 3.0\" ‚Üí Rejected (3.333... rounds to 3.3, not 3.0)\n\n### Comparison Options\n- **Absolute tolerance:** 1e-10 for very small differences\n- **Relative tolerance:** Optional for percentage-based comparisons\n- **Special values:** Handles Infinity, NaN, and -0 correctly\n\n## Capabilities & Limitations\n\n**Strengths:** \n- Handles numerical computations, unit conversions, comparisons, and mathematical functions through MathJS\n- Deterministic approximation handling without relying on LLM interpretation\n- Can make multiple calculation attempts to verify different parts of a statement\n- Early detection of symbolic math to avoid unnecessary API calls\n- Consistent and predictable comparison behavior\n\n**Limitations:** \n- Cannot handle symbolic mathematics (derivatives, integrals, proofs)\n- Limited to 5 rounds of tool calls with 60-second timeout\n- Returns `cannot_verify` for symbolic expressions or incomplete statements\n- Costs ~$0.02-0.05 per verification when using agent mode\n\n## Technical Architecture\n\n### Core Components\n\n1. **`numeric-comparison.ts`** - Deterministic comparison utilities\n   - `compareNumericValues()` - Main comparison function with approximation logic\n   - `countDecimalPlaces()` - Determines precision from stated values\n   - `roundToDecimalPlaces()` - Rounds computed values for fair comparison\n   - `parseEqualityStatement()` - Parses various equality operators\n\n2. **`index.ts`** - Main tool implementation\n   - `tryDirectEvaluation()` - Attempts direct MathJS evaluation\n   - `tryEvaluateEquality()` - Handles equality comparisons with deterministic logic\n   - `evaluateExpression()` - Tool for Claude to evaluate expressions\n   - `llmAssistedVerification()` - Falls back to LLM for complex cases\n\n### Implementation Details\n\n- **Agent approach:** Claude with tool access for complex expressions\n- **Direct evaluation:** Bypasses LLM for simple equality checks\n- **Cost optimization:** Early return for symbolic/incomplete expressions\n- **Session tracking:** Integrated with Helicone for usage monitoring\n- **Location:** Implementation in `/internal-packages/ai/src/tools/check-math-with-mathjs/`\n\n## Testing\n\nThe tool includes comprehensive test coverage:\n- **Unit tests:** `numeric-comparison.test.ts` - Tests comparison logic\n- **Parser tests:** `mathjs-parser-utils.test.ts` - Tests AST parsing and equality detection\n- **Integration tests:** `deterministic-comparison.integration.test.ts` - Tests with real MathJS evaluations\n- **E2E tests:** `check-math-with-mathjs.e2e.test.ts` - Full tool testing with Claude API\n\n## Architecture\n\nFor a detailed explanation of how the tool works internally, including data flow, design decisions, and the parser-based approach, see [ARCHITECTURE.md](./ARCHITECTURE.md).",
  "check-math": "# Check Mathematical Accuracy\n\nA pure LLM-based tool that analyzes mathematical statements for errors using Claude. Unlike the MathJS-based tools, this relies entirely on Claude's reasoning capabilities to verify calculations, logic, units, and notation.\n\n## How It Works\n\nThe tool sends mathematical statements directly to Claude for analysis. Claude evaluates the statement and returns a structured response indicating whether it's true, false, or cannot be verified, along with detailed reasoning and error categorization when applicable.\n\n## Capabilities & Limitations\n\n**Strengths:** Can handle conceptual mathematics (derivatives, integrals, proofs), word problems, and complex reasoning. Provides detailed explanations and categorizes errors by type (calculation, logic, unit, notation, conceptual) and severity.\n\n**Limitations:** May make arithmetic errors on complex calculations since it doesn't use a calculator. Non-deterministic - the same input might produce slightly different explanations. Costs ~$0.02 per check as it uses Claude Haiku.\n\n## Technical Details\n\n- **Response format:** Returns status (verified_true/verified_false/cannot_verify), explanation, reasoning, and optional error details with correction suggestions\n- **Error categorization:** Automatically classifies mathematical errors and assigns severity levels\n- **Cache seeding:** Uses deterministic cache seeds for more consistent responses\n- **Location:** Implementation in `/internal-packages/ai/src/tools/check-math/`",
  "check-math-hybrid": "# Hybrid Mathematical Checker\n\nA two-stage mathematical verification tool that combines computational and conceptual approaches. First attempts verification using MathJS (via an agentic Claude wrapper that can make multiple calculation attempts), then falls back to pure LLM analysis for statements that can't be computed.\n\n## How It Works\n\nThe tool executes two verification strategies in sequence:\n1. **MathJS Agent** - Uses Claude with MathJS tool access to attempt numerical verification. Claude can call MathJS multiple times to break down complex calculations.\n2. **LLM Fallback** - If MathJS can't verify (returns `cannot_verify`), falls back to pure Claude analysis for conceptual/symbolic math like derivatives, limits, or proofs.\n\n## Capabilities & Limitations\n\n**Can verify:** Basic arithmetic, numerical expressions with functions (sqrt, factorial, log), unit conversions (via MathJS), and conceptual mathematics like calculus and proofs (via LLM fallback).\n\n**Cannot handle:** Real-time symbolic algebra, step-by-step equation solving, or graphical representations. MathJS stage requires numerical values - it can't simplify \"x + x = 2x\" symbolically. The tool returns early for obviously symbolic statements (derivatives, integrals, limits) to save API costs.\n\n## Technical Details\n\n- **Cost:** ~$0.01-0.03 per verification (uses Claude Haiku for analysis)\n- **Response time:** 2-5 seconds typically, with 60-second timeout protection\n- **Output:** Returns which tool verified (mathjs/llm), explanation, and optional correction suggestions\n- **Location:** Implementation in `/internal-packages/ai/src/tools/check-math-hybrid/`",
  "extract-math-expressions": "# Extract Mathematical Expressions\n\nSpecialized tool that extracts ONLY mathematical expressions likely to contain errors (20%+ chance of being wrong). Works alongside fact and forecast extractors to avoid duplication.\n\n## How It Works\n\nUses Claude to identify mathematical expressions that appear incorrect, focusing on arithmetic errors, wrong calculations, and unit conversion mistakes. Deliberately filters out correct expressions, simple percentages, and factual/forecasting claims handled by other tools. Returns expressions with error likelihood scores and surrounding context.\n\n## Capabilities & Limitations\n\n**Strengths:** Focused extraction - only flags likely errors to reduce noise. Avoids overlap with fact-checking and forecasting tools. Includes context and character offsets for each expression. Estimates error likelihood (0-100) for prioritization.\n\n**Limitations:** Intentionally restrictive - won't extract correct math or simple expressions. Cannot verify correctness itself (use math checker tools for that). May miss subtle errors in complex formulas. Costs ~$0.02 per extraction.\n\n## Technical Details\n\n- **Extraction threshold:** Only expressions with 20%+ error likelihood\n- **Exclusions:** Correct math, simple percentages, factual claims, predictions\n- **Output:** Expression text, error likelihood, context, character offsets\n- **Temperature:** 0 for consistent extraction\n- **Location:** Implementation in `/internal-packages/ai/src/tools/extract-math-expressions/`",
  "extract-forecasting-claims": "# Extract Forecasting Claims\n\nAI tool for extracting and evaluating forecasting claims from text with multi-dimensional quality scoring.\n\n## What it does\n\n- **Identifies Predictions**: Extracts forecasting statements from text automatically\n- **Clarifies Vague Claims**: Rewrites unclear predictions for better precision\n- **Scores Quality**: Evaluates across four dimensions (precision, verifiability, importance, robustness)\n- **Extracts Metadata**: Identifies probabilities, dates, and resolution criteria\n- **Assesses Verifiability**: Determines how easily predictions can be verified\n\n## Scoring Dimensions (0-100)\n\n**Precision**: How specific and well-defined the prediction is (\"Tesla stock will reach $300 by Dec 2025\" vs \"Tesla will do well\")\n**Verifiability**: How easily the prediction can be verified (\"Unemployment below 4%\" vs \"People will be happier\")\n**Importance**: Significance and impact of the prediction (global vs local effects)\n**Robustness**: How well-supported the prediction appears (based on evidence/reasoning)\n\n## Score Interpretation\n\n- **70-100**: Excellent quality, worth tracking\n- **40-69**: Moderate quality, may need refinement\n- **0-39**: Poor quality, significant issues\n\n## Use Cases\n\n- **Research Analysis**: Evaluate predictions in papers and reports\n- **Content Review**: Assess prediction quality in articles and commentary\n- **Forecast Tracking**: Identify high-quality predictions worth monitoring\n- **Decision Support**: Evaluate predictions used in strategic planning\n\n## Integration\n\nWorks well with:\n- **Perplexity Research Tool**: Research background for predictions\n- **Fact Checker Tool**: Verify underlying assumptions\n- **Document Analysis Tools**: Process longer documents with multiple predictions\n\n## Important Notes\n\n- Clarifies vague predictions to improve precision and trackability\n- Scoring based on text analysis, not domain expertise\n- Cannot verify prediction accuracy (only evaluates quality)\n- Review clarified predictions to ensure original intent is preserved\n- Focus tracking efforts on high-scoring predictions\n\n## Limitations\n\nMay miss subtle predictions. Effectiveness varies with writing style and domain complexity.",
  "document-chunker": "# Intelligent Document Chunker\n\nMarkdown-aware document chunker that recursively splits text into optimized chunks while preserving document structure and context. Despite having multiple strategies in the code, currently only uses markdown-aware chunking.\n\n## How It Works\n\nParses markdown hierarchy to identify sections and headings, then recursively chunks content based on target word count (default 500 words). Handles code blocks, lists, and nested sections intelligently. Automatically merges small gaps between chunks (‚â§5 chars) and ensures no text is lost by creating filler chunks for larger gaps. Maintains heading context for each chunk.\n\n## Capabilities & Limitations\n\n**Strengths:** Preserves markdown structure and heading hierarchy. Handles code blocks without splitting them. Tracks line numbers and character offsets for each chunk. Returns metadata including chunk type (paragraph/section/code/list/heading/mixed) and completeness confidence. Zero cost - no LLM usage.\n\n**Limitations:** Currently only uses markdown strategy despite having semantic and hybrid methods in code. May not work well for non-markdown text. Target word count is approximate - actual chunks may vary. Cannot handle extremely nested structures beyond reasonable depth.\n\n## Technical Details\n\n- **Strategy:** Always uses markdown-aware chunking (ignores strategy parameter)\n- **Default target:** 500 words per chunk (configurable via targetWords)\n- **Character limits:** maxChunkSize (default 1500), minChunkSize (default 200)\n- **Output:** Chunks with offsets, line numbers, type metadata, and heading context\n- **Location:** Implementation in `/internal-packages/ai/src/tools/document-chunker/`",
  "fuzzy-text-locator": "# Fuzzy Text Locator\n\nMulti-strategy text location tool that finds text positions in documents using cascading search methods from exact matching to AI-powered semantic search.\n\n## What it does\n\n- **Locates Text**: Finds exact character positions of text within documents\n- **Multiple Strategies**: Uses 5 search methods in order of speed (exact ‚Üí fuzzy ‚Üí AI)\n- **Handles Variations**: Works with typos, quote differences, partial matches\n- **Character Precision**: Returns exact start/end positions in document\n- **Confidence Scoring**: Each match includes reliability score (0.0-1.0)\n\n## Search Strategy Cascade\n\n1. **Exact Match**: Perfect character match (fastest, confidence: 1.0)\n2. **Quote-Normalized**: Handles smart quotes, apostrophes (\"don't\" vs \"don't\")\n3. **Partial Match**: Finds truncated text (\"The research shows...\" matches longer quote)\n4. **Fuzzy Match**: Tolerates typos, case differences (\"mashine learning\" ‚Üí \"machine learning\")\n5. **LLM Fallback**: AI semantic search for paraphrased content (\"car drove fast\" ‚Üí \"automobile moved swiftly\")\n\n## Key Features\n\n- **Fast Performance**: Simple strategies first (most searches complete in <10ms)\n- **Quote Normalization**: Automatic handling of smart quotes, em-dashes, ellipses\n- **Partial Matching**: Works with truncated or incomplete text snippets\n- **Typo Tolerance**: Configurable fuzzy matching for common errors\n- **Semantic Search**: Optional AI fallback for meaning-based matching\n\n## Use Cases\n\n- **Plugin Text Location**: Find error text in documents for highlighting\n- **Quote Verification**: Locate quoted text with formatting variations\n- **Content Matching**: Find similar text across different documents\n- **Error Highlighting**: Position comments and annotations precisely\n\n## Configuration Options\n\n- **normalizeQuotes**: Handle quote/apostrophe variations\n- **partialMatch**: Match truncated text\n- **maxTypos**: Control fuzzy matching tolerance\n- **useLLMFallback**: Enable AI semantic search (slower but more flexible)\n\n## Important Notes\n\n- Strategies tried in speed order (fast ‚Üí slow)\n- Most searches complete without needing AI fallback\n- LLM fallback adds 500-2000ms but handles paraphrasing\n- Comprehensive test suite with 80+ edge cases\n- Used by analysis plugins for precise text positioning\n\n## Limitations\n\nPerformance decreases with document size. LLM fallback requires API access and increases response time.",
  "detect-language-convention": "# Detect Language Convention\n\nPure pattern-matching tool that detects US vs UK English conventions without LLM calls. Uses extensive dictionaries of spelling differences and weighted scoring to determine the dominant convention.\n\n## How It Works\n\nAnalyzes text against comprehensive US/UK word pair dictionaries (500+ word variations including -ize/-ise, -or/-our, -er/-re patterns). Applies pattern-based weighting (e.g., -ize/-ise differences weighted higher than -or/-our) and word frequency weights for common terms. Also detects document type (academic, technical, blog, casual) for additional context.\n\n## Capabilities & Limitations\n\n**Strengths:** Zero cost - no API usage. Deterministic and fast (<10ms). Returns confidence (0-1) and consistency scores. Provides evidence list showing which words were detected. Handles mixed conventions by calculating consistency metric. Analyzes up to 2000 characters by default (configurable).\n\n**Limitations:** Dictionary-based - won't catch words not in the dictionaries. Cannot detect Australian, Canadian, or other English variants. Requires sufficient distinctive words for accurate detection. May struggle with very short texts or texts without characteristic spellings.\n\n## Technical Details\n\n- **Dictionary size:** 500+ US/UK word pairs with variations\n- **Pattern weights:** Different patterns weighted by distinctiveness\n- **Output:** Convention (US/UK), confidence (0-1), consistency (0-1), evidence array, document type\n- **Location:** Implementation in `/internal-packages/ai/src/tools/detect-language-convention/`",
  "forecaster": "# Forecaster Tool\n\nA tool that generates probability forecasts using multiple independent Claude analyses.\n\n## Overview\n\nThe Forecaster Tool asks Claude to make independent probability assessments of a given question, then aggregates them using statistical methods to produce a final forecast with confidence levels.\n\n## Usage\n\n### API Endpoint\n```\nPOST /api/tools/forecaster\n```\n\n### Input Schema\n```typescript\n{\n  question: string;         // The question to forecast (1-500 chars)\n  context?: string;         // Additional context (max 1000 chars)\n  numForecasts?: number;    // Number of forecasts to generate (3-20, default: 6)\n  usePerplexity?: boolean;  // Whether to use Perplexity for research (default: false)\n}\n```\n\n### Output Schema\n```typescript\n{\n  probability: number;      // Aggregated probability (0-100)\n  description: string;      // Description of the forecast and reasoning\n  confidence: 'low' | 'medium' | 'high';  // Based on forecast agreement\n  individualForecasts: Array<{\n    probability: number;\n    reasoning: string;\n  }>;\n  statistics: {\n    mean: number;\n    median: number;\n    stdDev: number;\n    agreement: number;    // % of forecasts within 10 points of median\n  };\n}\n```\n\n## Example\n\n```typescript\nconst response = await fetch('/api/tools/forecaster', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer YOUR_TOKEN'\n  },\n  body: JSON.stringify({\n    question: \"Will AGI be achieved by 2030?\",\n    context: \"Recent advances in LLMs have accelerated AI progress\",\n    numForecasts: 6\n  })\n});\n\nconst result = await response.json();\n// {\n//   success: true,\n//   toolId: 'forecaster',\n//   result: {\n//     probability: 35,\n//     description: \"Based on 6 independent analyses...\",\n//     confidence: 'medium',\n//     individualForecasts: [...],\n//     statistics: {...}\n//   }\n// }\n```\n\n## Cost\n\nApproximately $0.05 per forecast (6 Claude calls).\n\n## Implementation Details\n\n- Uses multiple independent Claude calls to reduce bias\n- Removes statistical outliers before aggregation\n- Confidence levels based on forecast agreement:\n  - High: >66% of forecasts within 10 points of median\n  - Medium: 33-66% agreement\n  - Low: <33% agreement",
  "link-validator": "# Link Validator\n\nFast, comprehensive link checking tool that extracts and validates all external links in documents with detailed error classification.\n\n## What it does\n\n- **Finds All Links**: Automatically detects URLs in markdown, HTML, and plain text\n- **Multi-Strategy Validation**: Tests HEAD requests first, falls back to GET with different user agents\n- **Categorizes Errors**: Classifies failures (403 Forbidden, 404 Not Found, timeouts, network errors)\n- **Generates Statistics**: Provides link health summary and error breakdown\n- **Creates Highlights**: Positions comments for broken links in documents\n- **Zero LLM Usage**: Pure HTTP validation - fast and cost-effective\n\n## Error Types\n\n**NotFound (404)**: Page doesn't exist\n**Forbidden (403)**: Access denied (common with bot detection)\n**Timeout**: Request timed out\n**NetworkError**: DNS, SSL, or connection issues\n**RateLimited (429)**: Too many requests\n**ServerError (5xx)**: Server-side problems\n\n## Key Features\n\n- **Respectful Validation**: Uses delays between requests, tries multiple user agents\n- **Context-Aware Messages**: Adapts reporting based on predominant error types\n- **Batch Processing**: Handles up to 20 URLs per request (configurable)\n- **Redirect Handling**: Tracks final URLs after redirects\n- **Performance Focused**: 10-second timeout per request\n\n## Use Cases\n\n- **Research Papers**: Verify citation links and references\n- **Blog Posts**: Check external links for accessibility\n- **Documentation**: Ensure all referenced links work\n- **Content Quality**: Identify broken or inaccessible resources\n\n## Example Output\n\n**Access-restricted focus** (many 403s):\n\"üö´ Links Blocked by Access Restrictions - Found 8 inaccessible URLs, primarily due to access restrictions.\"\n\n**Broken links focus** (many 404s):\n\"‚ùå Broken Links Detected - Found 6 broken or non-existent URLs that may need updating.\"\n\n## Important Notes\n\n- No prescriptive recommendations - focuses on status reporting only\n- Many websites block automated access even when content exists\n- Always verify important links manually for critical documents\n- 403 errors often indicate bot detection, not broken content\n- Best used as first pass before human review\n\n## Limitations\n\nCannot access paywalled content. Some sites block all automated requests regardless of content availability.",
  "perplexity-research": "# Perplexity Research\n\nAI-powered research assistant that searches current web information to gather context, sources, and insights on any topic.\n\n## What it does\n\n- **Real-Time Web Search**: Accesses current information beyond AI training data\n- **Source Categorization**: Ranks sources by relevance (high/medium/low)\n- **Key Findings Extraction**: Identifies and highlights important insights\n- **Domain Targeting**: Optimizes searches for academic, news, technical, or market focus\n- **Comprehensive Results**: Returns summaries, sources, and metadata for verification\n\n## Focus Areas\n\n**General**: Broad web search across all sources\n**Academic**: Prioritizes scholarly articles and research papers\n**News**: Focuses on recent news and current events\n**Technical**: Emphasizes documentation and specifications\n**Market**: Targets financial and market information\n\n## Key Features\n\n- **Up-to-Date Information**: Not limited to training cutoff dates\n- **Configurable Results**: Control number of sources (3-10)\n- **Full Source Metadata**: URLs, titles, snippets for verification\n- **Automatic Summarization**: Concise summaries of research findings\n- **Timestamp Tracking**: Records when research was conducted\n\n## Use Cases\n\n- **Forecasting Research**: Gather recent developments for prediction tasks\n- **Fact-Checking Support**: Find current sources to verify claims\n- **Context Building**: Research background for document analysis\n- **Expert Perspectives**: Access recent expert opinions and analysis\n\n## Integration\n\nWorks well with:\n- **Fact Checker Tool**: Verify claims against current sources\n- **Extract Forecasting Claims**: Research background for predictions\n- **Document Analysis**: Provide context for content evaluation\n\n## Example Queries\n\n- \"Latest breakthroughs in large language model efficiency 2024\"\n- \"Current renewable energy investment trends and policy changes\"\n- \"Recent CRISPR safety advances and regulatory updates\"\n\n## Performance\n\n- **Response Time**: 2-5 seconds depending on query complexity\n- **Source Diversity**: Returns 5-10 high-quality sources typically\n- **Update Frequency**: Accesses information updated within hours/days\n- **Rate Management**: Automatic backoff for API limits\n\n## Important Notes\n\n- Be specific in queries for better results\n- Choose appropriate focus area for your research domain\n- Always verify sources by checking provided URLs\n- Track timestamps for time-sensitive research\n- Best used to inform other analysis tools\n\n## Limitations\n\nDependent on API availability. Results quality varies with query specificity. Cannot access paywalled content."
} as const;

export type ToolId = keyof typeof toolReadmes;

export function getToolReadme(toolId: string): string {
  const typedToolId = toolId as ToolId;
  return toolReadmes[typedToolId] || `# ${toolId}\n\n*README content not available*`;
}

/**
 * Auto-generated tool README content
 * Generated by scripts/generate-tool-readmes.ts
 * DO NOT EDIT MANUALLY
 * 
 * README Hash: 73da1a1cb2edcc440681dd7f0e1582c46d2472140a90e43147d8d94b61003d57
 */

export const toolReadmes = {
  "check-spelling-grammar": "# Spelling & Grammar Checker\n\nAI-powered tool for detecting and correcting spelling and grammar errors with severity ratings and detailed explanations.\n\n## What it does\n\n- **Detects Errors**: Identifies spelling mistakes and grammar issues\n- **Classifies Severity**: Rates errors as critical (70+), major (40-70), or minor (<40)\n- **Provides Corrections**: Suggests specific improvements with explanations\n- **Shows Location**: Pinpoints exact line numbers for each error\n\n## Common Error Types\n\n**Spelling**: Typos, misspelled words, confused words (their/there/they're)\n**Grammar**: Subject-verb disagreement, wrong tenses, punctuation errors\n\n## Use Cases\n\n- **Academic Writing**: Essays, research papers, publications\n- **Business Communication**: Emails, reports, proposals  \n- **Content Creation**: Blog posts, articles, marketing copy\n- **Learning**: Educational explanations help improve writing skills\n\n## Important Notes\n\n- AI may miss context-dependent errors or flag intentional style choices\n- Technical/specialized terms might be incorrectly flagged\n- Always review suggestions critically - not all are necessary corrections\n- Best used as a first pass before human proofreading\n- Multiple passes can catch additional issues after corrections are made\n\n## Limitations\n\nCannot replace human proofreading for critical documents. Accuracy varies with text complexity.",
  "extract-factual-claims": "# Extract Factual Claims\n\nAI-powered tool for extracting and categorizing factual claims from text with confidence scores and verifiability assessment.\n\n## What it does\n\n- **Identifies Claims**: Extracts factual statements from text automatically\n- **Classifies Types**: Categorizes as factual, statistical, historical, scientific, or other\n- **Assesses Verifiability**: Determines if claims can be verified through external sources\n- **Provides Confidence**: Scores each claim for extraction reliability\n- **Handles Multiple Claims**: Processes entire documents in a single operation\n\n## Claim Types\n\n**Factual**: General statements about events, people, or things (\"Paris is the capital of France\")\n**Statistical**: Numerical data and measurements (\"Unemployment rose 2.3% in 2023\")\n**Historical**: Past events and dates (\"World War II ended in 1945\")\n**Scientific**: Research findings and technical facts (\"Water boils at 100Â°C at sea level\")\n**Other**: Claims that don't fit standard categories\n\n## Use Cases\n\n- **Research Analysis**: Extract claims from academic papers and reports\n- **Content Verification**: Identify statements needing fact-checking\n- **Information Organization**: Structure factual data from large documents\n- **Quality Assurance**: Review content for proper claim support\n\n## Integration\n\nWorks well with:\n- **Fact Checker Tool**: Verify extracted claims for accuracy\n- **Perplexity Research Tool**: Find sources for claim verification\n- **Link Validator Tool**: Check referenced sources\n\n## Important Notes\n\n- AI may extract opinions as factual claims - always review results\n- Cannot verify claim accuracy (only identifies and categorizes them)\n- Effectiveness varies with text complexity and writing style\n- Check confidence scores - higher scores indicate more reliable extraction\n- Best used as first pass before human review\n\n## Limitations\n\nMay miss context-dependent or implicit claims. Performance varies by domain and document structure.",
  "fact-checker": "# Fact Checker\n\nAI-powered tool for verifying the accuracy of specific factual claims with detailed evidence and reasoning.\n\n## What it does\n\n- **Verifies Claims**: Analyzes specific claims for accuracy and truthfulness\n- **Provides Verdicts**: Returns true, false, partially-true, unverifiable, or outdated\n- **Explains Reasoning**: Detailed explanations with supporting evidence\n- **Suggests Corrections**: Offers accurate alternatives for false claims\n- **Assesses Confidence**: Indicates reliability of the verification\n\n## Verification Process\n\n1. Analyzes the claim against current knowledge and sources\n2. Determines accuracy with nuanced verdicts (not just true/false)\n3. Provides evidence and reasoning for the verdict\n4. Suggests corrections when claims are inaccurate or misleading\n\n## Verdict Types\n\n**True**: Claim is accurate and supported by reliable evidence\n**False**: Claim is demonstrably incorrect\n**Partially-true**: Claim contains accurate elements but is misleading or incomplete\n**Unverifiable**: Cannot be verified with available sources\n**Outdated**: Was true but no longer current\n\n## Use Cases\n\n- **Individual Claim Verification**: Check specific statements for accuracy\n- **Content Review**: Verify key claims in articles or documents\n- **Research Validation**: Confirm factual assertions in academic work\n- **Misinformation Detection**: Identify and correct false information\n\n## Integration\n\nWorks with **Extract Factual Claims** tool:\n1. Extract claims from documents\n2. Prioritize high-importance claims\n3. Verify selected claims for accuracy\n4. Generate comprehensive fact-check reports\n\n## Important Notes\n\n- Focuses on verifying specific claims (not extracting them)\n- Provides evidence-based reasoning for all verdicts\n- Best used for high-priority or controversial claims\n- Always includes confidence levels for reliability assessment\n\n## Limitations\n\nEffectiveness depends on claim specificity and available evidence sources. Cannot verify highly specialized or very recent claims.",
  "check-math-with-mathjs": "# Check Math with MathJS\n\n*README content not available*",
  "check-math": "# Check Mathematical Accuracy\n\n*README content not available*",
  "check-math-hybrid": "# Hybrid Mathematical Checker\n\n*README content not available*",
  "extract-math-expressions": "# Extract Mathematical Expressions\n\n*README content not available*",
  "extract-forecasting-claims": "# Extract Forecasting Claims\n\nAI tool for extracting and evaluating forecasting claims from text with multi-dimensional quality scoring.\n\n## What it does\n\n- **Identifies Predictions**: Extracts forecasting statements from text automatically\n- **Clarifies Vague Claims**: Rewrites unclear predictions for better precision\n- **Scores Quality**: Evaluates across four dimensions (precision, verifiability, importance, robustness)\n- **Extracts Metadata**: Identifies probabilities, dates, and resolution criteria\n- **Assesses Verifiability**: Determines how easily predictions can be verified\n\n## Scoring Dimensions (0-100)\n\n**Precision**: How specific and well-defined the prediction is (\"Tesla stock will reach $300 by Dec 2025\" vs \"Tesla will do well\")\n**Verifiability**: How easily the prediction can be verified (\"Unemployment below 4%\" vs \"People will be happier\")\n**Importance**: Significance and impact of the prediction (global vs local effects)\n**Robustness**: How well-supported the prediction appears (based on evidence/reasoning)\n\n## Score Interpretation\n\n- **70-100**: Excellent quality, worth tracking\n- **40-69**: Moderate quality, may need refinement\n- **0-39**: Poor quality, significant issues\n\n## Use Cases\n\n- **Research Analysis**: Evaluate predictions in papers and reports\n- **Content Review**: Assess prediction quality in articles and commentary\n- **Forecast Tracking**: Identify high-quality predictions worth monitoring\n- **Decision Support**: Evaluate predictions used in strategic planning\n\n## Integration\n\nWorks well with:\n- **Perplexity Research Tool**: Research background for predictions\n- **Fact Checker Tool**: Verify underlying assumptions\n- **Document Analysis Tools**: Process longer documents with multiple predictions\n\n## Important Notes\n\n- Clarifies vague predictions to improve precision and trackability\n- Scoring based on text analysis, not domain expertise\n- Cannot verify prediction accuracy (only evaluates quality)\n- Review clarified predictions to ensure original intent is preserved\n- Focus tracking efforts on high-scoring predictions\n\n## Limitations\n\nMay miss subtle predictions. Effectiveness varies with writing style and domain complexity.",
  "document-chunker": "# Intelligent Document Chunker\n\n*README content not available*",
  "fuzzy-text-locator": "# Fuzzy Text Locator\n\nMulti-strategy text location tool that finds text positions in documents using cascading search methods from exact matching to AI-powered semantic search.\n\n## What it does\n\n- **Locates Text**: Finds exact character positions of text within documents\n- **Multiple Strategies**: Uses 5 search methods in order of speed (exact â†’ fuzzy â†’ AI)\n- **Handles Variations**: Works with typos, quote differences, partial matches\n- **Character Precision**: Returns exact start/end positions in document\n- **Confidence Scoring**: Each match includes reliability score (0.0-1.0)\n\n## Search Strategy Cascade\n\n1. **Exact Match**: Perfect character match (fastest, confidence: 1.0)\n2. **Quote-Normalized**: Handles smart quotes, apostrophes (\"don't\" vs \"don't\")\n3. **Partial Match**: Finds truncated text (\"The research shows...\" matches longer quote)\n4. **Fuzzy Match**: Tolerates typos, case differences (\"mashine learning\" â†’ \"machine learning\")\n5. **LLM Fallback**: AI semantic search for paraphrased content (\"car drove fast\" â†’ \"automobile moved swiftly\")\n\n## Key Features\n\n- **Fast Performance**: Simple strategies first (most searches complete in <10ms)\n- **Quote Normalization**: Automatic handling of smart quotes, em-dashes, ellipses\n- **Partial Matching**: Works with truncated or incomplete text snippets\n- **Typo Tolerance**: Configurable fuzzy matching for common errors\n- **Semantic Search**: Optional AI fallback for meaning-based matching\n\n## Use Cases\n\n- **Plugin Text Location**: Find error text in documents for highlighting\n- **Quote Verification**: Locate quoted text with formatting variations\n- **Content Matching**: Find similar text across different documents\n- **Error Highlighting**: Position comments and annotations precisely\n\n## Configuration Options\n\n- **normalizeQuotes**: Handle quote/apostrophe variations\n- **partialMatch**: Match truncated text\n- **maxTypos**: Control fuzzy matching tolerance\n- **useLLMFallback**: Enable AI semantic search (slower but more flexible)\n\n## Important Notes\n\n- Strategies tried in speed order (fast â†’ slow)\n- Most searches complete without needing AI fallback\n- LLM fallback adds 500-2000ms but handles paraphrasing\n- Comprehensive test suite with 80+ edge cases\n- Used by analysis plugins for precise text positioning\n\n## Limitations\n\nPerformance decreases with document size. LLM fallback requires API access and increases response time.",
  "detect-language-convention": "# Detect Language Convention\n\n*README content not available*",
  "forecaster": "# Forecaster Tool\n\nA tool that generates probability forecasts using multiple independent Claude analyses.\n\n## Overview\n\nThe Forecaster Tool asks Claude to make independent probability assessments of a given question, then aggregates them using statistical methods to produce a final forecast with confidence levels.\n\n## Usage\n\n### API Endpoint\n```\nPOST /api/tools/forecaster\n```\n\n### Input Schema\n```typescript\n{\n  question: string;         // The question to forecast (1-500 chars)\n  context?: string;         // Additional context (max 1000 chars)\n  numForecasts?: number;    // Number of forecasts to generate (3-20, default: 6)\n  usePerplexity?: boolean;  // Whether to use Perplexity for research (default: false)\n}\n```\n\n### Output Schema\n```typescript\n{\n  probability: number;      // Aggregated probability (0-100)\n  description: string;      // Description of the forecast and reasoning\n  confidence: 'low' | 'medium' | 'high';  // Based on forecast agreement\n  individualForecasts: Array<{\n    probability: number;\n    reasoning: string;\n  }>;\n  statistics: {\n    mean: number;\n    median: number;\n    stdDev: number;\n    agreement: number;    // % of forecasts within 10 points of median\n  };\n}\n```\n\n## Example\n\n```typescript\nconst response = await fetch('/api/tools/forecaster', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer YOUR_TOKEN'\n  },\n  body: JSON.stringify({\n    question: \"Will AGI be achieved by 2030?\",\n    context: \"Recent advances in LLMs have accelerated AI progress\",\n    numForecasts: 6\n  })\n});\n\nconst result = await response.json();\n// {\n//   success: true,\n//   toolId: 'forecaster',\n//   result: {\n//     probability: 35,\n//     description: \"Based on 6 independent analyses...\",\n//     confidence: 'medium',\n//     individualForecasts: [...],\n//     statistics: {...}\n//   }\n// }\n```\n\n## Cost\n\nApproximately $0.05 per forecast (6 Claude calls).\n\n## Implementation Details\n\n- Uses multiple independent Claude calls to reduce bias\n- Removes statistical outliers before aggregation\n- Confidence levels based on forecast agreement:\n  - High: >66% of forecasts within 10 points of median\n  - Medium: 33-66% agreement\n  - Low: <33% agreement",
  "link-validator": "# Link Validator\n\nFast, comprehensive link checking tool that extracts and validates all external links in documents with detailed error classification.\n\n## What it does\n\n- **Finds All Links**: Automatically detects URLs in markdown, HTML, and plain text\n- **Multi-Strategy Validation**: Tests HEAD requests first, falls back to GET with different user agents\n- **Categorizes Errors**: Classifies failures (403 Forbidden, 404 Not Found, timeouts, network errors)\n- **Generates Statistics**: Provides link health summary and error breakdown\n- **Creates Highlights**: Positions comments for broken links in documents\n- **Zero LLM Usage**: Pure HTTP validation - fast and cost-effective\n\n## Error Types\n\n**NotFound (404)**: Page doesn't exist\n**Forbidden (403)**: Access denied (common with bot detection)\n**Timeout**: Request timed out\n**NetworkError**: DNS, SSL, or connection issues\n**RateLimited (429)**: Too many requests\n**ServerError (5xx)**: Server-side problems\n\n## Key Features\n\n- **Respectful Validation**: Uses delays between requests, tries multiple user agents\n- **Context-Aware Messages**: Adapts reporting based on predominant error types\n- **Batch Processing**: Handles up to 20 URLs per request (configurable)\n- **Redirect Handling**: Tracks final URLs after redirects\n- **Performance Focused**: 10-second timeout per request\n\n## Use Cases\n\n- **Research Papers**: Verify citation links and references\n- **Blog Posts**: Check external links for accessibility\n- **Documentation**: Ensure all referenced links work\n- **Content Quality**: Identify broken or inaccessible resources\n\n## Example Output\n\n**Access-restricted focus** (many 403s):\n\"ðŸš« Links Blocked by Access Restrictions - Found 8 inaccessible URLs, primarily due to access restrictions.\"\n\n**Broken links focus** (many 404s):\n\"âŒ Broken Links Detected - Found 6 broken or non-existent URLs that may need updating.\"\n\n## Important Notes\n\n- No prescriptive recommendations - focuses on status reporting only\n- Many websites block automated access even when content exists\n- Always verify important links manually for critical documents\n- 403 errors often indicate bot detection, not broken content\n- Best used as first pass before human review\n\n## Limitations\n\nCannot access paywalled content. Some sites block all automated requests regardless of content availability.",
  "perplexity-research": "# Perplexity Research\n\nAI-powered research assistant that searches current web information to gather context, sources, and insights on any topic.\n\n## What it does\n\n- **Real-Time Web Search**: Accesses current information beyond AI training data\n- **Source Categorization**: Ranks sources by relevance (high/medium/low)\n- **Key Findings Extraction**: Identifies and highlights important insights\n- **Domain Targeting**: Optimizes searches for academic, news, technical, or market focus\n- **Comprehensive Results**: Returns summaries, sources, and metadata for verification\n\n## Focus Areas\n\n**General**: Broad web search across all sources\n**Academic**: Prioritizes scholarly articles and research papers\n**News**: Focuses on recent news and current events\n**Technical**: Emphasizes documentation and specifications\n**Market**: Targets financial and market information\n\n## Key Features\n\n- **Up-to-Date Information**: Not limited to training cutoff dates\n- **Configurable Results**: Control number of sources (3-10)\n- **Full Source Metadata**: URLs, titles, snippets for verification\n- **Automatic Summarization**: Concise summaries of research findings\n- **Timestamp Tracking**: Records when research was conducted\n\n## Use Cases\n\n- **Forecasting Research**: Gather recent developments for prediction tasks\n- **Fact-Checking Support**: Find current sources to verify claims\n- **Context Building**: Research background for document analysis\n- **Expert Perspectives**: Access recent expert opinions and analysis\n\n## Integration\n\nWorks well with:\n- **Fact Checker Tool**: Verify claims against current sources\n- **Extract Forecasting Claims**: Research background for predictions\n- **Document Analysis**: Provide context for content evaluation\n\n## Example Queries\n\n- \"Latest breakthroughs in large language model efficiency 2024\"\n- \"Current renewable energy investment trends and policy changes\"\n- \"Recent CRISPR safety advances and regulatory updates\"\n\n## Performance\n\n- **Response Time**: 2-5 seconds depending on query complexity\n- **Source Diversity**: Returns 5-10 high-quality sources typically\n- **Update Frequency**: Accesses information updated within hours/days\n- **Rate Management**: Automatic backoff for API limits\n\n## Important Notes\n\n- Be specific in queries for better results\n- Choose appropriate focus area for your research domain\n- Always verify sources by checking provided URLs\n- Track timestamps for time-sensitive research\n- Best used to inform other analysis tools\n\n## Limitations\n\nDependent on API availability. Results quality varies with query specificity. Cannot access paywalled content."
} as const;

export type ToolId = keyof typeof toolReadmes;

export function getToolReadme(toolId: string): string {
  const typedToolId = toolId as ToolId;
  return toolReadmes[typedToolId] || `# ${toolId}\n\n*README content not available*`;
}
